<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hadoop,Java," />





  <link rel="alternate" href="/atom.xml" title="Wei.Cao" type="application/atom+xml" />






<meta name="description" content="自定义inputFormat需求无论hdfs还是mapreduce，对于小文件都有损效率，实践中，又难免面临处理大量小文件的场景，此时，就需要有相应解决方案 分析小文件的优化无非以下几种方式：  在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS 在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并 在mapreduce处理时，可采用combineInputForma">
<meta name="keywords" content="Hadoop,Java">
<meta property="og:type" content="article">
<meta property="og:title" content="MAPREDUCE进阶学习">
<meta property="og:url" content="http://yoursite.com/2017/07/02/mapreduce进阶学习/index.html">
<meta property="og:site_name" content="Wei.Cao">
<meta property="og:description" content="自定义inputFormat需求无论hdfs还是mapreduce，对于小文件都有损效率，实践中，又难免面临处理大量小文件的场景，此时，就需要有相应解决方案 分析小文件的优化无非以下几种方式：  在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS 在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并 在mapreduce处理时，可采用combineInputForma">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-03-12T10:42:37.990Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MAPREDUCE进阶学习">
<meta name="twitter:description" content="自定义inputFormat需求无论hdfs还是mapreduce，对于小文件都有损效率，实践中，又难免面临处理大量小文件的场景，此时，就需要有相应解决方案 分析小文件的优化无非以下几种方式：  在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS 在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并 在mapreduce处理时，可采用combineInputForma">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/07/02/mapreduce进阶学习/"/>





  <title>MAPREDUCE进阶学习 | Wei.Cao</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ad8fac4ab530dc35351b752a97b89b03";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Wei.Cao</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-board">
          <a href="/board/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            留言
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/02/mapreduce进阶学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei.Cao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/596cd3e8d520e.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wei.Cao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MAPREDUCE进阶学习</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-02T11:50:35+08:00">
                2017-07-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/07/02/mapreduce进阶学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count gitment-comments-count" data-xid="/2017/07/02/mapreduce进阶学习/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="自定义inputFormat"><a href="#自定义inputFormat" class="headerlink" title="自定义inputFormat"></a>自定义inputFormat</h2><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>无论hdfs还是mapreduce，对于小文件都有损效率，实践中，又难免面临处理大量小文件的场景，此时，就需要有相应解决方案</p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>小文件的优化无非以下几种方式：</p>
<ol>
<li>在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS</li>
<li>在业务处理之前，在HDFS上使用mapreduce程序对小文件进行合并</li>
<li>在mapreduce处理时，可采用combineInputFormat提高效率</li>
</ol>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><ul>
<li><p>程序的核心机制：</p>
<ul>
<li>自定义一个InputFormat</li>
<li>改写RecordReader，实现一次读取一个完整文件封装为KV</li>
<li>在输出时使用SequenceFileOutPutFormat输出合并文件</li>
</ul>
</li>
<li><p>代码如下：</p>
</li>
<li><p>自定义InputFromat</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public class WholeFileInputFormat extends</span><br><span class="line">		FileInputFormat&lt;NullWritable, BytesWritable&gt; &#123;</span><br><span class="line">	//设置每个小文件不可分片,保证一个小文件生成一个key-value键值对</span><br><span class="line">	@Override</span><br><span class="line">	protected boolean isSplitable(JobContext context, Path file) &#123;</span><br><span class="line">		return false;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public RecordReader&lt;NullWritable, BytesWritable&gt; createRecordReader(</span><br><span class="line">			InputSplit split, TaskAttemptContext context) throws IOException,</span><br><span class="line">			InterruptedException &#123;</span><br><span class="line">		WholeFileRecordReader reader = new WholeFileRecordReader();</span><br><span class="line">		reader.initialize(split, context);</span><br><span class="line">		return reader;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
</li>
<li><p>自定义RecordReader</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">class WholeFileRecordReader extends RecordReader&lt;NullWritable, BytesWritable&gt; &#123;</span><br><span class="line">	private FileSplit fileSplit;</span><br><span class="line">	private Configuration conf;</span><br><span class="line">	private BytesWritable value = new BytesWritable();</span><br><span class="line">	private boolean processed = false;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void initialize(InputSplit split, TaskAttemptContext context)</span><br><span class="line">			throws IOException, InterruptedException &#123;</span><br><span class="line">		this.fileSplit = (FileSplit) split;</span><br><span class="line">		this.conf = context.getConfiguration();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public boolean nextKeyValue() throws IOException, InterruptedException &#123;</span><br><span class="line">		if (!processed) &#123;</span><br><span class="line">			byte[] contents = new byte[(int) fileSplit.getLength()];</span><br><span class="line">			Path file = fileSplit.getPath();</span><br><span class="line">			FileSystem fs = file.getFileSystem(conf);</span><br><span class="line">			FSDataInputStream in = null;</span><br><span class="line">			try &#123;</span><br><span class="line">				in = fs.open(file);</span><br><span class="line">				IOUtils.readFully(in, contents, 0, contents.length);</span><br><span class="line">				value.set(contents, 0, contents.length);</span><br><span class="line">			&#125; finally &#123;</span><br><span class="line">				IOUtils.closeStream(in);</span><br><span class="line">			&#125;</span><br><span class="line">			processed = true;</span><br><span class="line">			return true;</span><br><span class="line">		&#125;</span><br><span class="line">		return false;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public NullWritable getCurrentKey() throws IOException,</span><br><span class="line">			InterruptedException &#123;</span><br><span class="line">		return NullWritable.get();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public BytesWritable getCurrentValue() throws IOException,</span><br><span class="line">			InterruptedException &#123;</span><br><span class="line">		return value;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public float getProgress() throws IOException &#123;</span><br><span class="line">		return processed ? 1.0f : 0.0f;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void close() throws IOException &#123;</span><br><span class="line">		// do nothing</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>定义mapreduce处理流程</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">public class SmallFilesToSequenceFileConverter extends Configured implements</span><br><span class="line">		Tool &#123;</span><br><span class="line">	static class SequenceFileMapper extends</span><br><span class="line">			Mapper&lt;NullWritable, BytesWritable, Text, BytesWritable&gt; &#123;</span><br><span class="line">		private Text filenameKey;</span><br><span class="line"></span><br><span class="line">		@Override</span><br><span class="line">		protected void setup(Context context) throws IOException,</span><br><span class="line">				InterruptedException &#123;</span><br><span class="line">			InputSplit split = context.getInputSplit();</span><br><span class="line">			Path path = ((FileSplit) split).getPath();</span><br><span class="line">			filenameKey = new Text(path.toString());</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		@Override</span><br><span class="line">		protected void map(NullWritable key, BytesWritable value,</span><br><span class="line">				Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">			context.write(filenameKey, value);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public int run(String[] args) throws Exception &#123;</span><br><span class="line">		Configuration conf = new Configuration();</span><br><span class="line">		System.setProperty(&quot;HADOOP_USER_NAME&quot;, &quot;hdfs&quot;);</span><br><span class="line">		String[] otherArgs = new GenericOptionsParser(conf, args)</span><br><span class="line">				.getRemainingArgs();</span><br><span class="line">		if (otherArgs.length != 2) &#123;</span><br><span class="line">			System.err.println(&quot;Usage: combinefiles &lt;in&gt; &lt;out&gt;&quot;);</span><br><span class="line">			System.exit(2);</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		Job job = Job.getInstance(conf,&quot;combine small files to sequencefile&quot;);</span><br><span class="line">//		job.setInputFormatClass(WholeFileInputFormat.class);</span><br><span class="line">		job.setOutputFormatClass(SequenceFileOutputFormat.class);</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(BytesWritable.class);</span><br><span class="line">		job.setMapperClass(SequenceFileMapper.class);</span><br><span class="line">		return job.waitForCompletion(true) ? 0 : 1;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public static void main(String[] args) throws Exception &#123;</span><br><span class="line">		int exitCode = ToolRunner.run(new SmallFilesToSequenceFileConverter(),</span><br><span class="line">				args);</span><br><span class="line">		System.exit(exitCode);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
</li>
</ul>
<h2 id="自定义outputFormat"><a href="#自定义outputFormat" class="headerlink" title="自定义outputFormat"></a>自定义outputFormat</h2><h3 id="需求-1"><a href="#需求-1" class="headerlink" title="需求"></a>需求</h3><p>现有一些原始日志需要做增强解析处理，流程：</p>
<ol>
<li>从原始日志文件中读取数据</li>
<li>根据日志中的一个URL字段到外部知识库中获取信息增强到原始日志</li>
<li>如果成功增强，则输出到增强结果目录；如果增强失败，则抽取原始数据中URL字段输出到待爬清单目录</li>
</ol>
<h3 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h3><p>程序的关键点是要在一个mapreduce程序中根据数据的不同输出两类结果到不同目录，这类灵活的输出需求可以通过自定义outputformat来实现</p>
<h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><p>实现要点：</p>
<ol>
<li>在mapreduce中访问外部资源</li>
<li>自定义outputformat，改写其中的recordwriter，改写具体输出数据的方法write()</li>
</ol>
<p>代码实现如下：</p>
<ul>
<li><p>数据库获取数据的工具</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">public class DBLoader &#123;</span><br><span class="line"></span><br><span class="line">	public static void dbLoader(HashMap&lt;String, String&gt; ruleMap) &#123;</span><br><span class="line">		Connection conn = null;</span><br><span class="line">		Statement st = null;</span><br><span class="line">		ResultSet res = null;</span><br><span class="line">		</span><br><span class="line">		try &#123;</span><br><span class="line">			Class.forName(&quot;com.mysql.jdbc.Driver&quot;);</span><br><span class="line">			conn = DriverManager.getConnection(&quot;jdbc:mysql://hdp-node01:3306/urlknowledge&quot;, &quot;root&quot;, &quot;root&quot;);</span><br><span class="line">			st = conn.createStatement();</span><br><span class="line">			res = st.executeQuery(&quot;select url,content from urlcontent&quot;);</span><br><span class="line">			while (res.next()) &#123;</span><br><span class="line">				ruleMap.put(res.getString(1), res.getString(2));</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">			</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			try&#123;</span><br><span class="line">				if(res!=null)&#123;</span><br><span class="line">					res.close();</span><br><span class="line">				&#125;</span><br><span class="line">				if(st!=null)&#123;</span><br><span class="line">					st.close();</span><br><span class="line">				&#125;</span><br><span class="line">				if(conn!=null)&#123;</span><br><span class="line">					conn.close();</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">			&#125;catch(Exception e)&#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line">		DBLoader db = new DBLoader();</span><br><span class="line">		HashMap&lt;String, String&gt; map = new HashMap&lt;String,String&gt;();</span><br><span class="line">		db.dbLoader(map);</span><br><span class="line">		System.out.println(map.size());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>自定义一个outputformat</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">public class LogEnhancerOutputFormat extends FileOutputFormat&lt;Text, NullWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public RecordWriter&lt;Text, NullWritable&gt; getRecordWriter(TaskAttemptContext context) throws IOException, InterruptedException &#123;</span><br><span class="line">	FileSystem fs = FileSystem.get(context.getConfiguration());</span><br><span class="line">    Path enhancePath = new Path(&quot;hdfs://hdp-node01:9000/flow/enhancelog/enhanced.log&quot;);</span><br><span class="line">    Path toCrawlPath = new Path(&quot;hdfs://hdp-node01:9000/flow/tocrawl/tocrawl.log&quot;);</span><br><span class="line"></span><br><span class="line">    FSDataOutputStream enhanceOut = fs.create(enhancePath);</span><br><span class="line">    FSDataOutputStream toCrawlOut = fs.create(toCrawlPath);</span><br><span class="line">    return new MyRecordWriter(enhanceOut,toCrawlOut);</span><br><span class="line">    </span><br><span class="line">   &#125;  </span><br><span class="line"></span><br><span class="line">    static class MyRecordWriter extends RecordWriter&lt;Text, NullWritable&gt;&#123;</span><br><span class="line">    </span><br><span class="line">        FSDataOutputStream enhanceOut = null;</span><br><span class="line">        FSDataOutputStream toCrawlOut = null;</span><br><span class="line">        </span><br><span class="line">        public MyRecordWriter(FSDataOutputStream enhanceOut, FSDataOutputStream toCrawlOut) &#123;</span><br><span class="line">            this.enhanceOut = enhanceOut;</span><br><span class="line">            this.toCrawlOut = toCrawlOut;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void write(Text key, NullWritable value) throws IOException, InterruptedException &#123;</span><br><span class="line">            //有了数据，你来负责写到目的地  —— hdfs</span><br><span class="line">            //判断，进来内容如果是带tocrawl的，就往待爬清单输出流中写 toCrawlOut</span><br><span class="line">            if(key.toString().contains(&quot;tocrawl&quot;))&#123;</span><br><span class="line">                toCrawlOut.write(key.toString().getBytes());</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                enhanceOut.write(key.toString().getBytes());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        @Override</span><br><span class="line">        public void close(TaskAttemptContext context) throws IOException, InterruptedException &#123;</span><br><span class="line">            if(toCrawlOut!=null)&#123;</span><br><span class="line">                toCrawlOut.close();</span><br><span class="line">            &#125;</span><br><span class="line">            if(enhanceOut!=null)&#123;</span><br><span class="line">                enhanceOut.close();</span><br><span class="line">            &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h2 id="自定义GroupingComparator"><a href="#自定义GroupingComparator" class="headerlink" title="自定义GroupingComparator"></a>自定义GroupingComparator</h2><h3 id="需求-2"><a href="#需求-2" class="headerlink" title="需求"></a>需求</h3><p>有如下订单数据</p>
<table>
<thead>
<tr>
<th>订单id</th>
<th>商品id</th>
<th>成交金额</th>
</tr>
</thead>
<tbody>
<tr>
<td>Order_0000001</td>
<td>Pdt_01</td>
<td>222.8</td>
</tr>
<tr>
<td>Order_0000001</td>
<td>Pdt_05</td>
<td>25.8</td>
</tr>
<tr>
<td>Order_0000002</td>
<td>Pdt_03</td>
<td>522.8</td>
</tr>
<tr>
<td>Order_0000002</td>
<td>Pdt_04</td>
<td>122.4</td>
</tr>
<tr>
<td>Order_0000003</td>
<td>Pdt_01</td>
<td>222.8</td>
</tr>
</tbody>
</table>
<p>现在需要求出每一个订单中成交金额最大的一笔交易</p>
<h3 id="分析-2"><a href="#分析-2" class="headerlink" title="分析"></a>分析</h3><ol>
<li>利用“订单id和成交金额”作为key，可以将map阶段读取到的所有订单数据按照id分区，按照金额排序，发送到reduce</li>
<li>在reduce端利用groupingcomparator将订单id相同的kv聚合成组，然后取第一个即是最大值</li>
</ol>
<h3 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h3><ul>
<li><p>自定义groupingcomparator</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 用于控制shuffle过程中reduce端对kv对的聚合逻辑</span><br><span class="line"> * @author duanhaitao@itcast.cn</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class ItemidGroupingComparator extends WritableComparator &#123;</span><br><span class="line"></span><br><span class="line">	protected ItemidGroupingComparator() &#123;</span><br><span class="line"></span><br><span class="line">		super(OrderBean.class, true);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public int compare(WritableComparable a, WritableComparable b) &#123;</span><br><span class="line">		OrderBean abean = (OrderBean) a;</span><br><span class="line">		OrderBean bbean = (OrderBean) b;</span><br><span class="line">		</span><br><span class="line">		//将item_id相同的bean都视为相同，从而聚合为一组</span><br><span class="line">		return abean.getItemid().compareTo(bbean.getItemid());</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>定义订单信息bean</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 订单信息bean，实现hadoop的序列化机制</span><br><span class="line"> * @author duanhaitao@itcast.cn</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class OrderBean implements WritableComparable&lt;OrderBean&gt;&#123;</span><br><span class="line">	private Text itemid;</span><br><span class="line">	private DoubleWritable amount;</span><br><span class="line"></span><br><span class="line">	public OrderBean() &#123;</span><br><span class="line">	&#125;</span><br><span class="line">	public OrderBean(Text itemid, DoubleWritable amount) &#123;</span><br><span class="line">		set(itemid, amount);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void set(Text itemid, DoubleWritable amount) &#123;</span><br><span class="line"></span><br><span class="line">		this.itemid = itemid;</span><br><span class="line">		this.amount = amount;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public Text getItemid() &#123;</span><br><span class="line">		return itemid;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public DoubleWritable getAmount() &#123;</span><br><span class="line">		return amount;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public int compareTo(OrderBean o) &#123;</span><br><span class="line">		int cmp = this.itemid.compareTo(o.getItemid());</span><br><span class="line">		if (cmp == 0) &#123;</span><br><span class="line"></span><br><span class="line">			cmp = -this.amount.compareTo(o.getAmount());</span><br><span class="line">		&#125;</span><br><span class="line">		return cmp;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void write(DataOutput out) throws IOException &#123;</span><br><span class="line">		out.writeUTF(itemid.toString());</span><br><span class="line">		out.writeDouble(amount.get());</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">	public void readFields(DataInput in) throws IOException &#123;</span><br><span class="line">		String readUTF = in.readUTF();</span><br><span class="line">		double readDouble = in.readDouble();</span><br><span class="line">		</span><br><span class="line">		this.itemid = new Text(readUTF);</span><br><span class="line">		this.amount= new DoubleWritable(readDouble);</span><br><span class="line">	&#125;</span><br><span class="line">  	@Override</span><br><span class="line">	public String toString() &#123;</span><br><span class="line">		return itemid.toString() + &quot;\t&quot; + amount.get();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>编写mapreduce处理流程</p>
<ul>
<li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 利用secondarysort机制输出每种item订单金额最大的记录</span><br><span class="line"> * @author duanhaitao@itcast.cn</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">public class SecondarySort &#123;</span><br><span class="line">	</span><br><span class="line">	static class SecondarySortMapper extends Mapper&lt;LongWritable, Text, OrderBean, NullWritable&gt;&#123;</span><br><span class="line">		</span><br><span class="line">		OrderBean bean = new OrderBean();</span><br><span class="line">		</span><br><span class="line">		@Override</span><br><span class="line">		protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">			String line = value.toString();</span><br><span class="line">			String[] fields = StringUtils.split(line, &quot;\t&quot;);</span><br><span class="line">			</span><br><span class="line">			bean.set(new Text(fields[0]), new DoubleWritable(Double.parseDouble(fields[1])));</span><br><span class="line">			</span><br><span class="line">			context.write(bean, NullWritable.get());</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	static class SecondarySortReducer extends Reducer&lt;OrderBean, NullWritable, OrderBean, NullWritable&gt;&#123;</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		//在设置了groupingcomparator以后，这里收到的kv数据 就是：  &lt;1001 87.6&gt;,null  &lt;1001 76.5&gt;,null  .... </span><br><span class="line">		//此时，reduce方法中的参数key就是上述kv组中的第一个kv的key：&lt;1001 87.6&gt;</span><br><span class="line">		//要输出同一个item的所有订单中最大金额的那一个，就只要输出这个key</span><br><span class="line">		@Override</span><br><span class="line">		protected void reduce(OrderBean key, Iterable&lt;NullWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">			context.write(key, NullWritable.get());</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	public static void main(String[] args) throws Exception &#123;</span><br><span class="line">		</span><br><span class="line">		Configuration conf = new Configuration();</span><br><span class="line">		Job job = Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		job.setJarByClass(SecondarySort.class);</span><br><span class="line">		</span><br><span class="line">		job.setMapperClass(SecondarySortMapper.class);</span><br><span class="line">		job.setReducerClass(SecondarySortReducer.class);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		job.setOutputKeyClass(OrderBean.class);</span><br><span class="line">		job.setOutputValueClass(NullWritable.class);</span><br><span class="line">		</span><br><span class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</span><br><span class="line">		//指定shuffle所使用的GroupingComparator类</span><br><span class="line">		job.setGroupingComparatorClass(ItemidGroupingComparator.class);</span><br><span class="line">		//指定shuffle所使用的partitioner类</span><br><span class="line">		job.setPartitionerClass(ItemIdPartitioner.class);</span><br><span class="line">		</span><br><span class="line">		job.setNumReduceTasks(3);</span><br><span class="line">		</span><br><span class="line">		job.waitForCompletion(true);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
</li>
</ul>
<h2 id="Mapreduce中的DistributedCache应用"><a href="#Mapreduce中的DistributedCache应用" class="headerlink" title="Mapreduce中的DistributedCache应用"></a>Mapreduce中的DistributedCache应用</h2><h3 id="Map端join案例"><a href="#Map端join案例" class="headerlink" title="Map端join案例"></a>Map端join案例</h3><h4 id="需求-3"><a href="#需求-3" class="headerlink" title="需求"></a>需求</h4><p>实现两个“表”的join操作，其中一个表数据量小，一个表很大，这种场景在实际中非常常见，比如“订单日志” join “产品信息”</p>
<h4 id="分析-3"><a href="#分析-3" class="headerlink" title="分析"></a>分析</h4><ul>
<li>原理阐述<ul>
<li>适用于关联表中有小表的情形；</li>
<li>可以将小表分发到所有的map节点，这样，map节点就可以在本地对自己所读到的大表数据进行join并输出最终结果</li>
<li>可以大大提高join操作的并发度，加快处理速度</li>
</ul>
</li>
<li>示例：先在mapper类中预先定义好小表，进行join</li>
<li>并用distributedcache机制将小表的数据分发到每一个maptask执行节点，从而每一个maptask节点可以从本地加载到小表的数据，进而在本地即可实现join</li>
</ul>
<h4 id="实现-3"><a href="#实现-3" class="headerlink" title="实现"></a>实现</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">public class TestDistributedCache &#123;</span><br><span class="line">	static class TestDistributedCacheMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt;&#123;</span><br><span class="line">		FileReader in = null;</span><br><span class="line">		BufferedReader reader = null;</span><br><span class="line">		HashMap&lt;String,String&gt; b_tab = new HashMap&lt;String, String&gt;();</span><br><span class="line">		String localpath =null;</span><br><span class="line">		String uirpath = null;</span><br><span class="line">		</span><br><span class="line">		//是在map任务初始化的时候调用一次</span><br><span class="line">		@Override</span><br><span class="line">		protected void setup(Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">			//通过这几句代码可以获取到cache file的本地绝对路径，测试验证用</span><br><span class="line">			Path[] files = context.getLocalCacheFiles();</span><br><span class="line">			localpath = files[0].toString();</span><br><span class="line">			URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">			</span><br><span class="line">			</span><br><span class="line">			//缓存文件的用法——直接用本地IO来读取</span><br><span class="line">			//这里读的数据是map task所在机器本地工作目录中的一个小文件</span><br><span class="line">			in = new FileReader(&quot;b.txt&quot;);</span><br><span class="line">			reader =new BufferedReader(in);</span><br><span class="line">			String line =null;</span><br><span class="line">			while(null!=(line=reader.readLine()))&#123;</span><br><span class="line">				</span><br><span class="line">				String[] fields = line.split(&quot;,&quot;);</span><br><span class="line">				b_tab.put(fields[0],fields[1]);</span><br><span class="line">				</span><br><span class="line">			&#125;</span><br><span class="line">			IOUtils.closeStream(reader);</span><br><span class="line">			IOUtils.closeStream(in);</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">		</span><br><span class="line">		@Override</span><br><span class="line">		protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">			//这里读的是这个map task所负责的那一个切片数据（在hdfs上）</span><br><span class="line">			 String[] fields = value.toString().split(&quot;\t&quot;);</span><br><span class="line">			 </span><br><span class="line">			 String a_itemid = fields[0];</span><br><span class="line">			 String a_amount = fields[1];</span><br><span class="line">			 </span><br><span class="line">			 String b_name = b_tab.get(a_itemid);</span><br><span class="line">			 </span><br><span class="line">			 // 输出结果  1001	98.9	banan</span><br><span class="line">			 context.write(new Text(a_itemid), new Text(a_amount + &quot;\t&quot; + &quot;:&quot; + localpath + &quot;\t&quot; +b_name ));</span><br><span class="line">			 </span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	public static void main(String[] args) throws Exception &#123;</span><br><span class="line">		</span><br><span class="line">		Configuration conf = new Configuration();</span><br><span class="line">		Job job = Job.getInstance(conf);</span><br><span class="line">		</span><br><span class="line">		job.setJarByClass(TestDistributedCache.class);</span><br><span class="line">		</span><br><span class="line">		job.setMapperClass(TestDistributedCacheMapper.class);</span><br><span class="line">		</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(LongWritable.class);</span><br><span class="line">		</span><br><span class="line">		//这里是我们正常的需要处理的数据所在路径</span><br><span class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</span><br><span class="line">		</span><br><span class="line">		//不需要reducer</span><br><span class="line">		job.setNumReduceTasks(0);</span><br><span class="line">		//分发一个文件到task进程的工作目录</span><br><span class="line">		job.addCacheFile(new URI(&quot;hdfs://hadoop-server01:9000/cachefile/b.txt&quot;));</span><br><span class="line">		</span><br><span class="line">		//分发一个归档文件到task进程的工作目录</span><br><span class="line">//		job.addArchiveToClassPath(archive);</span><br><span class="line"></span><br><span class="line">		//分发jar包到task节点的classpath下</span><br><span class="line">//		job.addFileToClassPath(jarfile);</span><br><span class="line">		</span><br><span class="line">		job.waitForCompletion(true);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Mapreduce的其他补充"><a href="#Mapreduce的其他补充" class="headerlink" title="Mapreduce的其他补充"></a>Mapreduce的其他补充</h2><h3 id="计数器应用"><a href="#计数器应用" class="headerlink" title="计数器应用"></a>计数器应用</h3><p>在实际生产代码中，常常需要将数据处理过程中遇到的不合规数据行进行全局计数，类似这种需求可以借助mapreduce框架中提供的全局计数器来实现</p>
<p>示例代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">public class MultiOutputs &#123;</span><br><span class="line">	//通过枚举形式定义自定义计数器</span><br><span class="line">	enum MyCounter&#123;MALFORORMED,NORMAL&#125;</span><br><span class="line"></span><br><span class="line">	static class CommaMapper extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123;</span><br><span class="line">		@Override</span><br><span class="line">		protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">			String[] words = value.toString().split(&quot;,&quot;);</span><br><span class="line"></span><br><span class="line">			for (String word : words) &#123;</span><br><span class="line">				context.write(new Text(word), new LongWritable(1));</span><br><span class="line">			&#125;</span><br><span class="line">			//对枚举定义的自定义计数器加1</span><br><span class="line">			context.getCounter(MyCounter.MALFORORMED).increment(1);</span><br><span class="line">			//通过动态设置自定义计数器加1</span><br><span class="line">			context.getCounter(&quot;counterGroupa&quot;, &quot;countera&quot;).increment(1);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h3 id="多job串联"><a href="#多job串联" class="headerlink" title="多job串联"></a>多job串联</h3><p>一个稍复杂点的处理逻辑往往需要多个mapreduce程序串联处理，多job的串联可以借助mapreduce框架的JobControl实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">ControlledJob cJob1 = new ControlledJob(job1.getConfiguration());</span><br><span class="line">      ControlledJob cJob2 = new ControlledJob(job2.getConfiguration());</span><br><span class="line">      ControlledJob cJob3 = new ControlledJob(job3.getConfiguration());</span><br><span class="line">     </span><br><span class="line">      // 设置作业依赖关系</span><br><span class="line">      cJob2.addDependingJob(cJob1);</span><br><span class="line">      cJob3.addDependingJob(cJob2);</span><br><span class="line"> </span><br><span class="line">      JobControl jobControl = new JobControl(&quot;RecommendationJob&quot;);</span><br><span class="line">      jobControl.addJob(cJob1);</span><br><span class="line">      jobControl.addJob(cJob2);</span><br><span class="line">      jobControl.addJob(cJob3);</span><br><span class="line"> </span><br><span class="line">      cJob1.setJob(job1);</span><br><span class="line">      cJob2.setJob(job2);</span><br><span class="line">      cJob3.setJob(job3);</span><br><span class="line"> </span><br><span class="line">      // 新建一个线程来运行已加入JobControl中的作业，开始进程并等待结束</span><br><span class="line">      Thread jobControlThread = new Thread(jobControl);</span><br><span class="line">      jobControlThread.start();</span><br><span class="line">      while (!jobControl.allFinished()) &#123;</span><br><span class="line">          Thread.sleep(500);</span><br><span class="line">      &#125;</span><br><span class="line">      jobControl.stop();</span><br><span class="line"> </span><br><span class="line">      return 0;</span><br></pre></td></tr></table></figure>
<h2 id="mapreduce参数优化"><a href="#mapreduce参数优化" class="headerlink" title="mapreduce参数优化"></a>mapreduce参数优化</h2><h3 id="资源相关参数"><a href="#资源相关参数" class="headerlink" title="资源相关参数"></a>资源相关参数</h3><ol>
<li>mapreduce.map.memory.mb: 一个Map Task可使用的资源上限（单位:MB），默认为1024。如果Map Task实际使用的资源量超过该值，则会被强制杀死。</li>
<li>mapreduce.reduce.memory.mb: 一个Reduce Task可使用的资源上限（单位:MB），默认为1024。如果Reduce Task实际使用的资源量超过该值，则会被强制杀死。</li>
<li>mapreduce.map.java.opts: Map Task的JVM参数，你可以在此配置默认的java heap size等参数, e.g.<br>“-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc” （@taskid@会被Hadoop框架自动换为相应的taskid）, 默认值: “”</li>
<li>mapreduce.reduce.java.opts: Reduce Task的JVM参数，你可以在此配置默认的java heap size等参数, e.g.<br>“-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc”, 默认值: “”</li>
<li>mapreduce.map.cpu.vcores: 每个Map task可使用的最多cpu core数目, 默认值: 1</li>
<li>mapreduce.map.cpu.vcores: 每个Reduce task可使用的最多cpu core数目, 默认值: 1<ol>
<li>yarn.scheduler.minimum-allocation-mb 1024</li>
</ol>
</li>
<li>yarn.scheduler.maximum-allocation-mb 8192</li>
<li>yarn.scheduler.minimum-allocation-vcores1</li>
<li>yarn.scheduler.maximum-allocation-vcores32</li>
</ol>
<h3 id="容错相关参数"><a href="#容错相关参数" class="headerlink" title="容错相关参数"></a>容错相关参数</h3><ol>
<li>mapreduce.map.maxattempts: 每个Map Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。</li>
<li>mapreduce.reduce.maxattempts: 每个Reduce Task最大重试次数，一旦重试参数超过该值，则认为Map Task运行失败，默认值：4。</li>
<li>mapreduce.map.failures.maxpercent: 当失败的Map Task失败比例超过该值为，整个作业则失败，默认值为0. 如果你的应用程序允许丢弃部分输入数据，则该该值设为一个大于0的值，比如5，表示如果有低于5%的Map Task失败（如果一个Map Task重试次数超过mapreduce.map.maxattempts，则认为这个Map Task失败，其对应的输入数据将不会产生任何结果），整个作业扔认为成功。</li>
<li>mapreduce.reduce.failures.maxpercent: 当失败的Reduce Task失败比例超过该值为，整个作业则失败，默认值为0.</li>
<li>mapreduce.task.timeout: Task超时时间，经常需要设置的一个参数，该参数表达的意思为：如果一个task在一定时间内没有任何进入，即不会读取新的数据，也没有输出数据，则认为该task处于block状态，可能是卡住了，也许永远会卡主，为了防止因为用户程序永远block住不退出，则强制设置了一个该超时时间（单位毫秒），默认是300000。如果你的程序对每条输入数据的处理时间过长（比如会访问数据库，通过网络拉取数据等），建议将该参数调大，该参数过小常出现的错误提示是“AttemptID:attempt_14267829456721_123456_m_000224_0 Timed out after 300 secsContainer killed by the ApplicationMaster.”。</li>
</ol>
<h3 id="本地运行mapreduce-作业"><a href="#本地运行mapreduce-作业" class="headerlink" title="本地运行mapreduce 作业"></a>本地运行mapreduce 作业</h3><p>设置以下几个参数:</p>
<ol>
<li>mapreduce.framework.name=local</li>
<li>mapreduce.jobtracker.address=local</li>
<li>fs.defaultFS=local</li>
</ol>
<h3 id="效率和稳定性相关参数"><a href="#效率和稳定性相关参数" class="headerlink" title="效率和稳定性相关参数"></a>效率和稳定性相关参数</h3><ol>
<li>mapreduce.map.speculative: 是否为Map Task打开推测执行机制，默认为false</li>
<li>mapreduce.reduce.speculative: 是否为Reduce Task打开推测执行机制，默认为false</li>
<li>mapreduce.job.user.classpath.first &amp; mapreduce.task.classpath.user.precedence：当同一个class同时出现在用户jar包和hadoop jar中时，优先使用哪个jar包中的class，默认为false，表示优先使用hadoop jar中的class。</li>
<li>mapreduce.input.fileinputformat.split.minsize: 每个Map Task处理的数据量（仅针对基于文件的Inputformat有效，比如TextInputFormat，SequenceFileInputFormat），默认为一个block大小，即 134217728。</li>
</ol>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/weixin.png" alt="Wei.Cao 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/zhifubao.png" alt="Wei.Cao 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    Wei.Cao
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://yoursite.com/2017/07/02/mapreduce进阶学习/" title="MAPREDUCE进阶学习">http://yoursite.com/2017/07/02/mapreduce进阶学习/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
            <a href="/tags/Java/" rel="tag"># Java</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/07/02/MAPREDUCE学习/" rel="next" title="MAPREDUCE学习">
                <i class="fa fa-chevron-left"></i> MAPREDUCE学习
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/07/02/MapReduce遇到问题/" rel="prev" title="MapReduce遇到问题">
                MapReduce遇到问题 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/596cd3e8d520e.png"
                alt="Wei.Cao" />
            
              <p class="site-author-name" itemprop="name">Wei.Cao</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">106</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">47</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          
<!--<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1614642&auto=1&height=66"></iframe>-->          
		

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#自定义inputFormat"><span class="nav-number">1.</span> <span class="nav-text">自定义inputFormat</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#需求"><span class="nav-number">1.1.</span> <span class="nav-text">需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析"><span class="nav-number">1.2.</span> <span class="nav-text">分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实现"><span class="nav-number">1.3.</span> <span class="nav-text">实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自定义outputFormat"><span class="nav-number">2.</span> <span class="nav-text">自定义outputFormat</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#需求-1"><span class="nav-number">2.1.</span> <span class="nav-text">需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析-1"><span class="nav-number">2.2.</span> <span class="nav-text">分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实现-1"><span class="nav-number">2.3.</span> <span class="nav-text">实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#自定义GroupingComparator"><span class="nav-number">3.</span> <span class="nav-text">自定义GroupingComparator</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#需求-2"><span class="nav-number">3.1.</span> <span class="nav-text">需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析-2"><span class="nav-number">3.2.</span> <span class="nav-text">分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实现-2"><span class="nav-number">3.3.</span> <span class="nav-text">实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mapreduce中的DistributedCache应用"><span class="nav-number">4.</span> <span class="nav-text">Mapreduce中的DistributedCache应用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Map端join案例"><span class="nav-number">4.1.</span> <span class="nav-text">Map端join案例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#需求-3"><span class="nav-number">4.1.1.</span> <span class="nav-text">需求</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分析-3"><span class="nav-number">4.1.2.</span> <span class="nav-text">分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#实现-3"><span class="nav-number">4.1.3.</span> <span class="nav-text">实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mapreduce的其他补充"><span class="nav-number">5.</span> <span class="nav-text">Mapreduce的其他补充</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#计数器应用"><span class="nav-number">5.1.</span> <span class="nav-text">计数器应用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多job串联"><span class="nav-number">5.2.</span> <span class="nav-text">多job串联</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapreduce参数优化"><span class="nav-number">6.</span> <span class="nav-text">mapreduce参数优化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#资源相关参数"><span class="nav-number">6.1.</span> <span class="nav-text">资源相关参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#容错相关参数"><span class="nav-number">6.2.</span> <span class="nav-text">容错相关参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#本地运行mapreduce-作业"><span class="nav-number">6.3.</span> <span class="nav-text">本地运行mapreduce 作业</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#效率和稳定性相关参数"><span class="nav-number">6.4.</span> <span class="nav-text">效率和稳定性相关参数</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wei.Cao</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  







<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    

    
      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: '1498967435000', 
            owner: 'huaxiaowei',
            repo: 'gitment-comments',
            
            lang: "zh-Hans# Force language, or auto switch by theme" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: 'a5317db783a77a762d0b32c444be681f8a55daed',
            
                client_id: 'e725b4cc6235cd482ba5'
            }});
        gitment.render('gitment-container');
      }

      
      renderGitment();
      
      </script>
    







  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
